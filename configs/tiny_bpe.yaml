seed: 1337
out_dir: runs/tiny_bpe
vocab_size: 1000
data:
  train_file: data/tinyshakespeare_200k.txt
model:
  d_model: 128
  n_layer: 3
  n_head: 4
  ctx_len: 128
  dropout: 0.1
train:
  batch_size: 64
  lr: 3e-4
  epochs: 2
  log_every: 50
  grad_clip: 1.0
